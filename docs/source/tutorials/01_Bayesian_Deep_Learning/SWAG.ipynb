{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push SWAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we run SWAG using PusH. SWAG stands for Stochastic Weight Averaging Gaussian, and it is used to build a distribution of parameters for a pre trained network by averaging parameter values over a set number of swag epochs. We begin by training a standard neural network for some number of epochs, then we start tracking and calculating the first and second moments of our model's parameters. The first moment is a running average of our parameters, updated after each swag epoch. The second moment is simply the first moment squared. After training for swag epochs, we use the first and second moments to sample parameter states.\n",
    "\n",
    "To get an inference result, we choose to sample say 20 parameter states, and average the predictions from these 20. The first and second moment defines our distribution to sample from, and can be a simple gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiments.nns.simplenet.simplenet\n",
    "from experiments.nns.simplenet.simplenet import SimpleNet\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = SimpleNet(num_classes=10, in_chans= 1, scale=1, network_idx=1, mode=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "\n",
    "notebook_directory = os.path.dirname(os.path.abspath(\"deep_ensemble_mnist.ipynb\"))\n",
    "# Navigate to the parent folder (assuming \"usr\" and \"home\" are at the same level)\n",
    "parent_directory = os.path.abspath(os.path.join(notebook_directory, \"..\",\"..\",\"..\",\"..\",\"..\",\"..\",\"..\"))\n",
    "\n",
    "# Construct the path to the ImageNet directory\n",
    "mnist_directory = os.path.abspath(os.path.join(parent_directory, \"/usr/data1/vision/data/\"))\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load the MNIST training dataset\n",
    "train_dataset = datasets.MNIST(root=mnist_directory, train=True, download=False, transform=transform)\n",
    "\n",
    "# Load the MNIST test dataset\n",
    "test_dataset = datasets.MNIST(root=mnist_directory, train=False, download=False, transform=transform)\n",
    "\n",
    "# Save the subset indices inside mnist_directory\n",
    "subset_save_path = os.path.join(mnist_directory, \"subset_indices.pth\")\n",
    "\n",
    "# Load the subset indices from mnist_directory\n",
    "loaded_subset_indices = torch.load(subset_save_path)\n",
    "\n",
    "# Create the subset using the loaded indices\n",
    "loaded_train_subset = torch.utils.data.Subset(train_dataset, loaded_subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(loaded_train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:06<00:25,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(2.1985)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:12<00:18,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(1.7891)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:18<00:12,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(1.4921)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:25<00:06,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(1.2514)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:31<00:00,  6.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(1.0594)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:07<00:28,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(0.9079)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:14<00:21,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(0.7706)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:21<00:14,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(0.6616)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:29<00:07,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(0.5624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:36<00:00,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch loss tensor(0.4836)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import push.bayes.swag\n",
    "\n",
    "num_ensembles = 2\n",
    "swag_epochs = 5\n",
    "pretrain_epochs = 5\n",
    "lr = 1e-3\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "four_particle_mswag = push.bayes.swag.train_mswag(\n",
    "    train_loader,\n",
    "    loss_fn,\n",
    "    pretrain_epochs,\n",
    "    swag_epochs,\n",
    "    SimpleNet, 10, 1, 1, 1, 2,\n",
    "    num_devices=2,\n",
    "    num_models = 4,\n",
    "    lr = lr\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_four_model_outputs = four_particle_mswag.posterior_pred(test_loader, loss_fn, num_samples=2, mode=\"median\")\n",
    "mode_four_model_outputs = four_particle_mswag.posterior_pred(test_loader, loss_fn, num_samples=2, mode=\"mode\")\n",
    "mean_four_model_outputs = four_particle_mswag.posterior_pred(test_loader, loss_fn, num_samples=2, mode=\"mean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_four_model_outputs:  tensor([7, 2, 1,  ..., 4, 5, 6])\n",
      "mean_four_model_outputs:  tensor([7, 2, 1,  ..., 4, 5, 6])\n",
      "mode_four_model_outputs:  tensor([7, 2, 1,  ..., 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print(\"median_four_model_outputs: \", median_four_model_outputs)\n",
    "print(\"mean_four_model_outputs: \", mean_four_model_outputs)\n",
    "print(\"mode_four_model_outputs: \", mode_four_model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "push_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
