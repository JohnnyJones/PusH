{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push Bayesian Deep Learning Tutorial\n",
    "## Introduction\n",
    "\n",
    "In this notebook we will demonstrate the usage of Push to run a deep ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import push.bayes.ensemble\n",
    "\n",
    "# =============================================================================\n",
    "# Simple Dataset + Neural Network\n",
    "# =============================================================================\n",
    "\n",
    "class RandDataset(Dataset):\n",
    "    def __init__(self, D):\n",
    "        self.xs = torch.randn(128*10, D)\n",
    "        self.ys = torch.randn(128*10, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.xs[idx], self.ys[idx]\n",
    "\n",
    "\n",
    "class MiniNN(nn.Module):\n",
    "    def __init__(self, D):\n",
    "        super(MiniNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(D, D)\n",
    "        self.fc2 = nn.Linear(D, D)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.ReLU()(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class BiggerNN(nn.Module):\n",
    "    def __init__(self, n, D):\n",
    "        super(BiggerNN, self).__init__()\n",
    "        self.minis = []\n",
    "        self.n = n\n",
    "        for i in range(0, n):\n",
    "            self.minis += [MiniNN(D)]\n",
    "            self.add_module(\"mini_layer\"+str(i), self.minis[-1])\n",
    "        self.fc = nn.Linear(D, 1)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i in range(0, self.n):\n",
    "            x = self.minis[i](x)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/jtsegaye/anaconda3/envs/push_exp/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/jtsegaye/anaconda3/envs/push_exp/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'BiggerNN' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m num_ensembles \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m push\u001b[39m.\u001b[39;49mbayes\u001b[39m.\u001b[39;49mensemble\u001b[39m.\u001b[39;49mtrain_deep_ensemble(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     dataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mMSELoss(),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     epochs,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     BiggerNN, L, D,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     num_ensembles\u001b[39m=\u001b[39;49mnum_ensembles\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsrv-hss-157-54.at.sfsu.edu/home/jtsegaye/push/docs/source/tutorials/01_Bayesian_Deep_Learning/Bayesian_Deep_Learning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[0;32m~/push/push/bayes/ensemble.py:76\u001b[0m, in \u001b[0;36mtrain_deep_ensemble\u001b[0;34m(dataloader, loss_fn, epochs, nn, num_devices, cache_size, view_size, num_ensembles, mk_optim, ensemble_entry, ensemble_state, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_deep_ensemble\u001b[39m(dataloader: Callable, loss_fn: Callable, epochs: \u001b[39mint\u001b[39m,\n\u001b[1;32m     73\u001b[0m                         nn: Callable, \u001b[39m*\u001b[39margs, num_devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, cache_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, view_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m,\n\u001b[1;32m     74\u001b[0m                         num_ensembles\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, mk_optim\u001b[39m=\u001b[39mmk_optim,\n\u001b[1;32m     75\u001b[0m                         ensemble_entry\u001b[39m=\u001b[39m_deep_ensemble_main, ensemble_state\u001b[39m=\u001b[39m{}) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     ensemble \u001b[39m=\u001b[39m Ensemble(nn, \u001b[39m*\u001b[39;49margs, num_devices\u001b[39m=\u001b[39;49mnum_devices, cache_size\u001b[39m=\u001b[39;49mcache_size, view_size\u001b[39m=\u001b[39;49mview_size)\n\u001b[1;32m     77\u001b[0m     ensemble\u001b[39m.\u001b[39mbayes_infer(dataloader, epochs, loss_fn\u001b[39m=\u001b[39mloss_fn, num_ensembles\u001b[39m=\u001b[39mnum_ensembles, mk_optim\u001b[39m=\u001b[39mmk_optim,\n\u001b[1;32m     78\u001b[0m                          ensemble_entry\u001b[39m=\u001b[39mensemble_entry, ensemble_state\u001b[39m=\u001b[39mensemble_state)\n\u001b[1;32m     79\u001b[0m     \u001b[39mreturn\u001b[39;00m ensemble\u001b[39m.\u001b[39mp_parameters()\n",
      "File \u001b[0;32m~/push/push/bayes/ensemble.py:45\u001b[0m, in \u001b[0;36mEnsemble.__init__\u001b[0;34m(self, mk_nn, num_devices, cache_size, view_size, *args)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, mk_nn: Callable, \u001b[39m*\u001b[39margs: \u001b[39many\u001b[39m, num_devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, cache_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, view_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[39msuper\u001b[39;49m(Ensemble, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(mk_nn, \u001b[39m*\u001b[39;49margs, num_devices\u001b[39m=\u001b[39;49mnum_devices, cache_size\u001b[39m=\u001b[39;49mcache_size, view_size\u001b[39m=\u001b[39;49mview_size)\n",
      "File \u001b[0;32m~/push/push/bayes/infer.py:20\u001b[0m, in \u001b[0;36mInfer.__init__\u001b[0;34m(self, mk_nn, num_devices, cache_size, view_size, *args)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mview_size \u001b[39m=\u001b[39m view_size\n\u001b[1;32m     19\u001b[0m \u001b[39m# Create a PusH Distribution\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_dist \u001b[39m=\u001b[39m ppush\u001b[39m.\u001b[39;49mPusH(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmk_nn, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size, view_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mview_size)\n\u001b[1;32m     21\u001b[0m atexit\u001b[39m.\u001b[39mregister(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cleanup)\n",
      "File \u001b[0;32m~/push/push/push.py:56\u001b[0m, in \u001b[0;36mPusH.__init__\u001b[0;34m(self, mk_module, cache_size, view_size, *args)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mview_size \u001b[39m=\u001b[39m view_size\n\u001b[1;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 56\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init()\n\u001b[1;32m     58\u001b[0m \u001b[39m# Tasks and results\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_future_id \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/push/push/push.py:90\u001b[0m, in \u001b[0;36mPusH._init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m p\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     89\u001b[0m \u001b[39m# Acknowledge that device event loops have been started\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_out_queues[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrank]\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(msg, NodeEvtLoopInitMSG):\n\u001b[1;32m     92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFatal error ... inconsistent message state \u001b[39m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m<string>:2\u001b[0m, in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/push_exp/lib/python3.10/multiprocessing/managers.py:818\u001b[0m, in \u001b[0;36mBaseProxy._callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    815\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tls\u001b[39m.\u001b[39mconnection\n\u001b[1;32m    817\u001b[0m conn\u001b[39m.\u001b[39msend((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id, methodname, args, kwds))\n\u001b[0;32m--> 818\u001b[0m kind, result \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mrecv()\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m#RETURN\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    821\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/push_exp/lib/python3.10/multiprocessing/connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 250\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[1;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n",
      "File \u001b[0;32m~/anaconda3/envs/push_exp/lib/python3.10/multiprocessing/connection.py:414\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_recv_bytes\u001b[39m(\u001b[39mself\u001b[39m, maxsize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv(\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    415\u001b[0m     size, \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m!i\u001b[39m\u001b[39m\"\u001b[39m, buf\u001b[39m.\u001b[39mgetvalue())\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m size \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/push_exp/lib/python3.10/multiprocessing/connection.py:379\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m remaining \u001b[39m=\u001b[39m size\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m remaining \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 379\u001b[0m     chunk \u001b[39m=\u001b[39m read(handle, remaining)\n\u001b[1;32m    380\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m    381\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "L = 10\n",
    "D = 20\n",
    "dataset = RandDataset(D)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "epochs = 10\n",
    "num_ensembles = 3\n",
    "push.bayes.ensemble.train_deep_ensemble(\n",
    "    dataloader,\n",
    "    torch.nn.MSELoss(),\n",
    "    epochs,\n",
    "    BiggerNN, L, D,\n",
    "    num_ensembles=num_ensembles\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "push_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
