{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f512d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dehuang/.pyenv/versions/3.9.6/lib/python3.9/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "from os.path import exists\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import ast\n",
    "import scipy as sp\n",
    "import scipy.stats as sps\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "#...\n",
    "\n",
    "font = {'family' : 'times',\n",
    "        'size'   : 14}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e049daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, run):\n",
    "        self.name = run.name\n",
    "        self.config = run.config\n",
    "        self.summary = run.summary\n",
    "        self.history = run.history()\n",
    "        self.tags = run.tags\n",
    "        self.run = run\n",
    "        \n",
    "    def get_id(self):\n",
    "        return (self.config['formula'],self.config['mol_idx'])\n",
    "        \n",
    "    def get_history(self):\n",
    "        return np.array(list(self.history['additional_steps'])).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6ec7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(project):\n",
    "    api = wandb.Api()\n",
    "    entity = \"bogp\"\n",
    "    hdata = []\n",
    "    runs = api.runs(entity + \"/\" + project)\n",
    "    for run in tqdm(runs):\n",
    "        try:\n",
    "            hdata.append(Experiment(run))\n",
    "        except:\n",
    "            pass\n",
    "    return hdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65509dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7051b22779994f018393638786c1961a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw = fetch(\"scale_master\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a06a3",
   "metadata": {},
   "source": [
    "# Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50275ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = {}\n",
    "for exp in raw:\n",
    "    if exp.run.group == \"bayes4\":\n",
    "        print(exp.name)\n",
    "        exps[exp.config[\"num_particles\"]] = exp\n",
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(exps, p):\n",
    "    if p == 32:\n",
    "        # huh? why doesn't fetch work\n",
    "        d = {0: [968, 0, 0, 0, 0, 3, 5, 3, 1, 0], 1: [0, 1119, 2, 3, 0, 1, 2, 1, 7, 0], 2: [6, 1, 996, 8, 2, 1, 4, 6, 8, 0], 3: [0, 0, 1, 984, 0, 6, 0, 2, 13, 4], 4: [2, 0, 3, 0, 969, 1, 1, 2, 1, 3], 5: [5, 0, 1, 12, 1, 859, 10, 2, 2, 0], 6: [5, 2, 1, 0, 4, 3, 941, 0, 2, 0], 7: [2, 4, 6, 9, 0, 0, 0, 996, 4, 7], 8: [2, 1, 3, 4, 6, 3, 4, 1, 946, 4], 9: [4, 5, 6, 8, 30, 6, 0, 7, 4, 939]}\n",
    "    elif p == 64:\n",
    "        # huh? why doesn't fetch work\n",
    "        d = {0: [971, 0, 0, 2, 0, 2, 3, 1, 1, 0], 1: [0, 1120, 2, 3, 0, 2, 2, 3, 2, 1], 2: [6, 3, 994, 9, 0, 2, 1, 10, 7, 0], 3: [0, 0, 10, 977, 0, 10, 0, 5, 2, 6], 4: [4, 1, 4, 0, 946, 0, 5, 0, 0, 22], 5: [5, 0, 4, 11, 1, 862, 5, 1, 1, 2], 6: [7, 3, 2, 0, 4, 7, 932, 0, 3, 0], 7: [2, 2, 11, 6, 0, 0, 0, 995, 3, 9], 8: [2, 1, 5, 8, 5, 2, 1, 3, 941, 6], 9: [5, 2, 1, 6, 11, 4, 0, 6, 1, 973]}\n",
    "    else:\n",
    "        d = ast.literal_eval(exps[p].history.orig_dist0[11])\n",
    "    if p == 32:\n",
    "        # huh? why doesn't fetch work\n",
    "        d_swag = {0: [973, 0, 0, 0, 0, 1, 2, 1, 3, 0], 1: [0, 1123, 3, 2, 0, 1, 2, 1, 3, 0], 2: [6, 0, 1011, 0, 1, 1, 2, 7, 4, 0], 3: [0, 0, 3, 994, 0, 6, 0, 2, 3, 2], 4: [2, 0, 0, 0, 971, 1, 5, 1, 0, 2], 5: [3, 0, 1, 3, 1, 878, 4, 0, 1, 1], 6: [7, 2, 0, 0, 3, 2, 942, 0, 2, 0], 7: [3, 4, 9, 4, 1, 0, 0, 1003, 1, 3], 8: [4, 1, 2, 6, 3, 3, 1, 1, 953, 0], 9: [4, 6, 2, 5, 22, 4, 0, 8, 3, 955]}\n",
    "    else:\n",
    "        d_swag = ast.literal_eval(exps[p].history.max_dist0[len(exps[p].history.max_dist0) - 1])\n",
    "    misclass = 0\n",
    "    misclass_swag = 0\n",
    "    total = 0\n",
    "    for c in range(10):\n",
    "        misclass += sum(d[c]) - d[c][c]\n",
    "        total += sum(d[c])\n",
    "        misclass_swag += sum(d_swag[c]) - d_swag[c][c]\n",
    "        # print(\"Orig\", c, sps.entropy([x / sum(d[c]) for x in d[c]]))\n",
    "        # print(\"Swag\", c, sps.entropy([x / sum(d_swag[c]) for x in d_swag[c]]))\n",
    "    print(\"original misclass\", misclass, \"mswag misclass\", misclass_swag)\n",
    "    return 1 - (misclass/total), 1- (misclass_swag/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883e8c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [1, 2, 4, 8, 16, 32]\n",
    "orig = []\n",
    "mswag = []\n",
    "for p in ps:\n",
    "    m1, m2 = calc(exps, p)\n",
    "    orig += [m1]\n",
    "    mswag += [m2]\n",
    "plt.plot(ps, orig, label='Standard', marker='s', linestyle=\"--\" )\n",
    "plt.plot(ps, mswag, label=\"Multi-Swag\", marker='o', linestyle=\":\")\n",
    "plt.xlabel(\"Particles\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Standard Training vs. Multi-Swag on MNIST\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for p in ps:\n",
    "    params += [exps[p].config[\"num_params\"]]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, mswag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a1e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"parameters\": params,\n",
    "    \"original accuracy\": orig,\n",
    "    \"particles\": ps,\n",
    "    \"mswag accuracy\": mswag,\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_latex(buf=\"table_width.tex\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00403f3",
   "metadata": {},
   "source": [
    "# Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569c1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes5 = {}\n",
    "for exp in raw:\n",
    "    if exp.run.group == \"bayes5\":\n",
    "        print(exp.name)\n",
    "        bayes5[exp.config[\"num_particles\"]] = exp\n",
    "bayes5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa195d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc2(exps, p):\n",
    "    if p == 32:\n",
    "        d= {0: [974, 0, 0, 0, 1, 0, 2, 1, 2, 0], 1: [0, 1126, 6, 0, 0, 1, 2, 0, 0, 0], 2: [4, 0, 1008, 4, 1, 1, 3, 7, 4, 0], 3: [0, 0, 8, 991, 0, 4, 0, 4, 3, 0], 4: [3, 1, 2, 0, 957, 1, 6, 0, 0, 12], 5: [3, 0, 2, 9, 0, 868, 8, 1, 0, 1], 6: [4, 3, 1, 1, 4, 6, 936, 0, 3, 0], 7: [2, 4, 11, 4, 0, 0, 0, 994, 2, 11], 8: [8, 0, 4, 3, 5, 3, 4, 2, 941, 4], 9: [5, 3, 0, 4, 8, 2, 1, 3, 3, 980]}\n",
    "    else:\n",
    "        d = ast.literal_eval(exps[p].history.orig_dist0[11])\n",
    "    d_swag = ast.literal_eval(exps[p].history.max_dist0[len(exps[p].history.max_dist0) - 1])\n",
    "    misclass = 0\n",
    "    misclass_swag = 0\n",
    "    total = 0\n",
    "    for c in range(10):\n",
    "        misclass += sum(d[c]) - d[c][c]\n",
    "        total += sum(d[c])\n",
    "        misclass_swag += sum(d_swag[c]) - d_swag[c][c]\n",
    "        # print(\"Orig\", c, sps.entropy([x / sum(d[c]) for x in d[c]]))\n",
    "        # print(\"Swag\", c, sps.entropy([x / sum(d_swag[c]) for x in d_swag[c]]))\n",
    "    print(\"original misclass\", misclass, \"mswag misclass\", misclass_swag)\n",
    "    return 1 - (misclass/total), 1 - (misclass_swag/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c0b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for p in ps:\n",
    "    params += [bayes5[p].config[\"num_params\"]]\n",
    "orig = []\n",
    "mswag = []\n",
    "for p in ps:\n",
    "    m1, m2 = calc2(bayes5, p)\n",
    "    orig += [m1]\n",
    "    mswag += [m2]\n",
    "    \n",
    "df = pd.DataFrame({\n",
    "    \"parameters\": params,\n",
    "    \"original accuracy\": orig,\n",
    "    \"particles\": ps,\n",
    "    \"mswag accuracy\": mswag,\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe7eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_latex(buf=\"table_depth.tex\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d0de13",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [1, 2, 4, 8, 16, 32]\n",
    "orig = []\n",
    "mswag = []\n",
    "for p in ps:\n",
    "    m1, m2 = calc2(exps, p)\n",
    "    orig += [m1]\n",
    "    mswag += [m2]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ps, mswag, label=\"Multi-Swag\", marker='o', linestyle=\":\")\n",
    "ax.plot(ps, orig, label='Standard', marker='s', linestyle=\"--\" )\n",
    "\n",
    "def foo(x):\n",
    "    print(x)\n",
    "    return exps[x].config[\"num_params\"]\n",
    "\n",
    "params_to_p = {}\n",
    "for p in ps:\n",
    "    params_to_p[exps[p].config[\"num_params\"]] = p\n",
    "\n",
    "def foo_inv(x):\n",
    "    return params_to_p[x]\n",
    "    \n",
    "secax = ax.secondary_xaxis('top', functions=(foo, foo_inv))\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Particles\")\n",
    "ax.set_ylabel(\"Acurracy\")\n",
    "ax.set_title(\"Standard Training vs. Multi-Swag on MNIST\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0dbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
